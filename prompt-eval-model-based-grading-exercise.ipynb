{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30e50d2",
   "metadata": {},
   "source": [
    "Generating test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c036bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9453c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-sonnet-4-0\"\n",
    "client = Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50102c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "    if stop_sequences:\n",
    "        params[\"stop_sequences\"] = stop_sequences\n",
    "    \n",
    "    response = client.messages.create(**params)\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2169a26",
   "metadata": {},
   "source": [
    "Model Based Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "995a59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Test Data with Code\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate an evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects, each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"task\": \"Description of task\",\n",
    "    \"format\": \"json\" or \"python\" or \"regex\",\n",
    "    \"solution_criteria\": \"Key criteria for evaluating the solution\"\n",
    "  },\n",
    "  ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a single regex\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```code\")\n",
    "    text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eedfa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'task': \"Create a JSON policy document that allows an IAM user to read objects from a specific S3 bucket named 'my-app-logs' and list the bucket contents\", 'format': 'json', 'solution_criteria': 'JSON must be valid IAM policy syntax with correct Version, Statement structure, Effect set to Allow, Principal or Resource specified correctly, and Actions including s3:GetObject and s3:ListBucket for the specified bucket ARN'}, {'task': 'Write a Python function that takes an AWS CloudWatch log event and extracts the timestamp, log level, and message from a typical application log line format', 'format': 'python', 'solution_criteria': 'Function must accept a log event parameter, correctly parse standard log format (timestamp, level, message), handle common log levels (INFO, ERROR, WARN, DEBUG), return structured data (dict or tuple), and include basic error handling for malformed input'}, {'task': 'Create a regex pattern that validates AWS Lambda function names according to AWS naming rules', 'format': 'regex', 'solution_criteria': 'Regex must enforce Lambda naming constraints: 1-64 characters long, alphanumeric characters and hyphens only, cannot start or end with hyphen, case sensitive, and properly anchored to match entire string'}]\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset\n",
    "dataset = generate_dataset()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10698e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to a JSON file\n",
    "with open(r'dataset/test-case-dataset3.json', 'w') as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d85856b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grade a test case + output using a model\n",
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Criteria you should use to evaluate the solution:\n",
    "<criteria>\n",
    "{test_case[\"solution_criteria\"]}\n",
    "</criteria>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d3805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes a test case into Claude\n",
    "def run_prompt(test_case):\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case[\"task\"]}\n",
    "\n",
    "* Respond only with Python, JSON, or a plain Regex\n",
    "* Do not add any comments or commentary or explanation\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```code\")\n",
    "    output = chat(messages, stop_sequences=[\"```\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a31db714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to validate the output structure\n",
    "import re\n",
    "import ast\n",
    "\n",
    "\n",
    "def validate_json(text):\n",
    "    try:\n",
    "        json.loads(text.strip())\n",
    "        return 10\n",
    "    except json.JSONDecodeError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_python(text):\n",
    "    try:\n",
    "        ast.parse(text.strip())\n",
    "        return 10\n",
    "    except SyntaxError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_regex(text):\n",
    "    try:\n",
    "        re.compile(text.strip())\n",
    "        return 10\n",
    "    except re.error:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def grade_syntax(response, test_case):\n",
    "    format = test_case[\"format\"]\n",
    "    if format == \"json\":\n",
    "        return validate_json(response)\n",
    "    elif format == \"python\":\n",
    "        return validate_python(response)\n",
    "    else:\n",
    "        return validate_regex(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c96056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a single test case and grade the output\n",
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    model_score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    syntax_score = grade_syntax(output, test_case)\n",
    "\n",
    "    score = (model_score + syntax_score) / 2\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "977553c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "071645e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 8.166666666666666\n"
     ]
    }
   ],
   "source": [
    "with open(r\"dataset/test-case-dataset3.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c099edd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"I'll write a Python function to validate AWS S3 bucket names according to the AWS naming conventions you specified.\\n\\n```python\\nimport re\\n\\ndef validate_s3_bucket_name(bucket_name):\\n    \\\"\\\"\\\"\\n    Validates whether an AWS S3 bucket name follows AWS naming conventions.\\n    \\n    AWS S3 bucket naming rules:\\n    - Must be between 3 and 63 characters long\\n    - Can consist only of lowercase letters, numbers, and hyphens\\n    - Must not contain consecutive hyphens\\n    - Must not start or end with a hyphen\\n    - Must not start or end with a period (additional AWS rule)\\n    - Must not contain underscores or other special characters\\n    - Must not be formatted as an IP address (additional AWS rule)\\n    \\n    Args:\\n        bucket_name (str): The bucket name to validate\\n        \\n    Returns:\\n        bool: True if the bucket name is valid, False otherwise\\n    \\\"\\\"\\\"\\n    \\n    # Check if bucket_name is a string\\n    if not isinstance(bucket_name, str):\\n        return False\\n    \\n    # Check length (3-63 characters)\\n    if len(bucket_name) < 3 or len(bucket_name) > 63:\\n        return False\\n    \\n    # Check if it starts or ends with hyphen\\n    if bucket_name.startswith('-') or bucket_name.endswith('-'):\\n        return False\\n    \\n    # Check if it starts or ends with period (additional AWS rule)\\n    if bucket_name.startswith('.') or bucket_name.endswith('.'):\\n        return False\\n    \\n    # Check for consecutive hyphens\\n    if '--' in bucket_name:\\n        return False\\n    \\n    # Check for consecutive periods (additional AWS rule)\\n    if '..' in bucket_name:\\n        return False\\n    \\n    # Check if it contains only lowercase letters, numbers, hyphens, and periods\\n    if not re.match(r'^[a-z0-9.-]+$', bucket_name):\\n        return False\\n    \\n    # Check if it's formatted as an IP address (additional AWS rule)\\n    if re.match(r'^\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+$', bucket_name):\\n        return False\\n    \\n    return True\\n\\ndef validate_s3_bucket_name_strict(bucket_name):\\n    \\\"\\\"\\\"\\n    Validates S3 bucket name with only the rules specified in the original request.\\n    \\n    Rules applied:\\n    - Must be between 3 and 63 characters long\\n    - Can consist only of lowercase letters, numbers, and hyphens\\n    - Must not contain consecutive hyphens\\n    - Must not start or end with a hyphen\\n    \\n    Args:\\n        bucket_name (str): The bucket name to validate\\n        \\n    Returns:\\n        bool: True if the bucket name is valid, False otherwise\\n    \\\"\\\"\\\"\\n    \\n    # Check if bucket_name is a string\\n    if not isinstance(bucket_name, str):\\n        return False\\n    \\n    # Check length (3-63 characters)\\n    if len(bucket_name) < 3 or len(bucket_name) > 63:\\n        return False\\n    \\n    # Check if it starts or ends with hyphen\\n    if bucket_name.startswith('-') or bucket_name.endswith('-'):\\n        return False\\n    \\n    # Check for consecutive hyphens\\n    if '--' in bucket_name:\\n        return False\\n    \\n    # Check if it contains only lowercase letters, numbers, and hyphens\\n    if not re.match(r'^[a-z0-9-]+$', bucket_name):\\n        return False\\n    \\n    return True\\n\\n# Test cases\\nif __name__ == \\\"__main__\\\":\\n    test_cases = [\\n        # Valid bucket names\\n        (\\\"my-bucket\\\", True),\\n        (\\\"test123\\\", True),\\n        (\\\"my-test-bucket-123\\\", True),\\n        (\\\"a\\\" * 63, True),  # Maximum length\\n        (\\\"abc\\\", True),     # Minimum length\\n        \\n        # Invalid bucket names\\n        (\\\"\\\", False),                    # Too short\\n        (\\\"ab\\\", False),                  # Too short\\n        (\\\"a\\\" * 64, False),             # Too long\\n        (\\\"-mybucket\\\", False),          #\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a Python function that validates whether an AWS S3 bucket name follows AWS naming conventions (3-63 characters, lowercase letters/numbers/hyphens only, no consecutive hyphens, doesn't start/end with hyphen)\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution correctly implements a sliding window approach to find all occurrences of a substring. The core logic is sound with proper index tracking and result collection. However, it lacks robustness in handling edge cases and would benefit from input validation to prevent runtime errors. The algorithm is efficient but could be more production-ready with better error handling.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a JSON object representing an AWS IAM policy that grants read-only access to the S3 bucket 'my-app-logs' and all objects within it:\\n\\n```json\\n{\\n  \\\"Version\\\": \\\"2012-10-17\\\",\\n  \\\"Statement\\\": [\\n    {\\n      \\\"Sid\\\": \\\"ListBucketAccess\\\",\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Action\\\": [\\n        \\\"s3:ListBucket\\\",\\n        \\\"s3:GetBucketLocation\\\"\\n      ],\\n      \\\"Resource\\\": \\\"arn:aws:s3:::my-app-logs\\\"\\n    },\\n    {\\n      \\\"Sid\\\": \\\"ReadObjectAccess\\\",\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Action\\\": [\\n        \\\"s3:GetObject\\\",\\n        \\\"s3:GetObjectVersion\\\"\\n      ],\\n      \\\"Resource\\\": \\\"arn:aws:s3:::my-app-logs/*\\\"\\n    }\\n  ]\\n}\\n```\\n\\nThis IAM policy includes:\\n\\n1. **First Statement** - Grants permissions on the bucket itself:\\n   - `s3:ListBucket`: Allows listing the contents of the bucket\\n   - `s3:GetBucketLocation`: Allows getting the bucket's region\\n   - Resource: `arn:aws:s3:::my-app-logs` (the bucket ARN)\\n\\n2. **Second Statement** - Grants permissions on objects within the bucket:\\n   - `s3:GetObject`: Allows reading/downloading objects\\n   - `s3:GetObjectVersion`: Allows reading specific versions of objects (useful if versioning is enabled)\\n   - Resource: `arn:aws:s3:::my-app-logs/*` (all objects within the bucket)\\n\\nThe policy follows the principle of least privilege by only granting read-only permissions and being specific to the 'my-app-logs' bucket.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a JSON object representing an AWS IAM policy that grants read-only access to a specific S3 bucket named 'my-app-logs' and all objects within it\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution demonstrates solid programming fundamentals with clean, readable code and proper validation. However, it lacks robust error handling mechanisms and testing coverage, which are essential for production-ready code. The implementation appears functionally correct but could be more resilient to unexpected inputs.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a regex pattern that matches valid AWS EC2 instance IDs:\\n\\n```regex\\n^i-[0-9a-f]{8}([0-9a-f]{9})?$\\n```\\n\\n**Explanation:**\\n- `^` - Start of string anchor\\n- `i-` - Literal characters \\\"i-\\\"\\n- `[0-9a-f]{8}` - Exactly 8 hexadecimal characters (0-9 or a-f)\\n- `([0-9a-f]{9})?` - Optional group of exactly 9 more hexadecimal characters\\n- `$` - End of string anchor\\n\\n**Alternative pattern using alternation:**\\n```regex\\n^i-([0-9a-f]{8}|[0-9a-f]{17})$\\n```\\n\\n**Explanation of alternative:**\\n- `^` - Start of string anchor\\n- `i-` - Literal characters \\\"i-\\\"\\n- `([0-9a-f]{8}|[0-9a-f]{17})` - Either 8 OR 17 hexadecimal characters\\n- `$` - End of string anchor\\n\\n**Examples of valid matches:**\\n- `i-1234567a` (8 characters)\\n- `i-1234567890abcdef1` (17 characters)\\n\\n**Examples of invalid matches:**\\n- `i-123` (too few characters)\\n- `i-123456789` (9 characters, not 8 or 17)\\n- `i-1234567g` (contains 'g', not valid hex)\\n\\nBoth patterns work correctly, but the first one is slightly more efficient as it builds upon the required 8 characters rather than checking two separate length conditions.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a regex pattern that matches valid AWS EC2 instance IDs (format: i- followed by 8 or 17 hexadecimal characters)\"\n",
      "    },\n",
      "    \"score\": 0,\n",
      "    \"reasoning\": \"I cannot provide a meaningful code review without seeing the actual task description and solution code. The evaluation template is well-structured, but requires the specific content to analyze strengths like algorithm choice, code quality, error handling, and potential improvements.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Examining the Results\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f26958",
   "metadata": {},
   "source": [
    "Each result contains three key pieces of information:\n",
    "\n",
    "- output: The complete response from Claude\n",
    "- test_case: The original test case that was processed\n",
    "- score: The evaluation score (currently hardcoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
